\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{Global Blending on Sparse Ratings in the Netflix Prize Dataset}


\author{
Timothy Ozimek\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.} \\
304 Fincastle Drive\\
Cary, NC 27513
\texttt{teozimek@ncsu.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

%\begin{abstract}
%The abstract paragraph should be indented 1/2~inch (3~picas) on both left and
%right-hand margins. Use 10~point type, with a vertical spacing of 11~points.
%The word \textbf{Abstract} must be centered, bold, and in point size 12. Two
%line spaces precede the abstract. The abstract must be limited to one
%paragraph.
%\end{abstract}

\section{Background}

The movie service, Netflix, offers users the choice of watching several thousand movies on demand.  While the service now offers a highly popular online, on-demand, streaming service, in the past, operations were run through a mail DVD system.  A user of the service could request a certain number of movies at any given time up to a limit.  After watching and returning the DVDs a customer could receive new movies for as quickly as the mail delivery service could deliver them.  Along with the movies, Netflix provided a list of recommended movies based on a user's viewing preferences.  A viewer can voluntarily rate movies they've seen with the understanding that their rating would guide Netflix in suggesting new movies.  The more ratings they gave, the better the recommendations became.

To provide this service, Netflix wrote the software tool, {\it Cinematch }.  This tool used a combination of machine learning and data mining algorithms to perform its duties.  One technique is prominently featured:  recommender systems.  The intuition behind these systems is based on how word-of-mouth conversations spread news of a product.  These conversations occur between friends and acquaintances who tend to share common opinions over a variety of topics.  Likes and dislikes accordingly tend to coincide.  

The field of data mining and machine learning has observed this relationship and formalized the task as a recommender system (need citation).  Such systems tend to employ the technique of collaborative filtering.  In short, this method scours data, looking for similarities in rating patterns, much like word-of-mouth works among similar friends, but at a far larger scale.  The result of this similarity seach will produce or filter a group of similar users from which a ratings estimate can be computed.

A variety of algorithms have been adopted with two standing large, item-based collaborative filtering (IBCF) and user-based collaborative filtering (UBCF).  The names of each imply their method of search.  IBCF finds similarity of items, in this case movies, and recommends based how similar a movie is to another.  Likewise UBCF establishes similarity through the intuitive word-of-mouth approach by comparing similar user ratings.

To stimulate research in improving their recommender system, Netflix offered the Netflix prize in 2006.  The objective was tantalizingly simple: be the first team to improve recommendations by 10\% over {\it Cinematch } and receive \$1 million.  Without delving too far into details, contestants were given a dataset of over 100 million user ratings of 17700 movies.  Against this dataset algorithms could be devised, tested, and submitted to Netflix for testing.  Netflix would run the submission against a hidden testset.  A simple root-mean-square-error would be computed per tested rating to arrive at a final score.  This score was the metric compared against {\it Cinematch } to determine the winner.

The prize was captured in September 2009 by the team "BellKor's Pragmatic Chaos", a group of professional statisticians and machine learning experts.  Their methods were sophisticated, entirely new and were comprised of 107 predictor algorithms run as an ensemble to produce ratings. At their core, however, they were recommender systems that had advanced ways of producing better similarity metrics.

The objective of this paper is less ambitious than the Netflix Prize.  The combined efforts of the winning team included well over 2000 hours of work for their preliminary solution where even their simplest algorithms took 45 minutes to run; several searches spanned over many hours.  The scope is beyond what can be provided in less than a semester's time.  

It was noted in "BellKor's Pragmatic Chaos"'s work that data sparsity was the main adversary that needed to be overcome.  Along these lines, this project will focus on exploring remedies to this issue by using more information from the dataset.  In particular, along with similarity of ratings, when sparsity offers little new information, global information on the movie such as average ratings and variance, as well as user bias, will be considered in weighing a score.  The further idea is that the sparser the data the more the algorithms will rely on global metrics and will taper-off as more similar information is provided.  Time of rating may also be considered to see if it offers better estimates.

The setup will rely on the {\it recommederlab } tool suite.  The purpose of this suite to to expose a sandbox experimental environment for recommender systems.  Support is provided for UBCF and IBCF systems as well as variants of singular value decomposition (SVD) and hybrid solutions.  Aside from user movie ratings, also were provided date of rating, title of movie, and DVD release data of movie.  Briefly, a bag-of-words approach was considered for identifying movie genres but was rejected outright because of too many proper names.  Additional support will be provided by C++ routines used to clean data, and provide training and test sets. 

%Each contains an ID, date, and rating supplied by a Netflix consumer.  The movie file provides a unique movie ID, release date, and text name for the movie.  

\section{Method}

The dataset is comprised of over 100 million ratings of 17700 movies from 480,000 users.  17700 text files, one per movie, contains a user id, rating, and date per line in ASCII comma-separated format.  A movie ID value was given on the first line of the file as an integer number.  A separate file gives the movie title for a given ID.  User IDs were arbitrary integers assigned by Netflix that stripped away personally identifying information.  The same ID is used by a user for all movies rated in the given data set.  Ratings are ordinal integer values from 1 to 5, with 1 indicating the worst rating and 5 the best.  Dates are also given in month-day-year format.  


The overall experiment will follow the guidelines for evaluation as set by Netflix.  A test set (not provided) will query the recommender system which will give a decimal rating for the user based on that user's prior movie ratings.  Netflix secretly held the actual rating given by the user.  Errors will be tabulated using the root-mean-square-error formula:

$$ RMSE = \sqrt{\frac{\sum_{i=1}^N (\hat{y_i} - y_i)^2}{N}} $$

While the data are considered clean by Netflix, it is enormous, occupying over 1.5 GB of space on 17700 separate text files.  Exploration of the space revealed that for many of the functions in recommenderlab, the memory constraints were insufficient to hold the data.  To get around this issue, a computer program was developed to sample recommendations from the overall merged dataset.  Parameters given include the number of users, number of movies, and random seed.  The program runs in two passes.  The first pass collects all of the users from the randomly chosen movies.  From this user list, random users are chosen up to the input parameter.  A file is then produced with these sampled selections.  The file is passed to another program which measures bulk statistics to ensure ratings follow a similar distribution as the overall dataset.  Additional user metrics are compared to ensure the number of user ratings scales with the diminished movie count.

From the sampled data set, RMSE will be computed with k=10 cross-validations (k value subject to change pending on runtime) against each global recommender method.  This procedure will be replicated across all valid sample sets.

A first priority is to establish rankings based on bulk metrics through average ratings.  This is the starting point for the Netflix prize contributions.  Against portions of this dataset this yields 1.05475 RMSE, similar to other findings.

From here ICBF and UCBF models will be explored.  Parameters considered will be number of nearest neighbors (k-NN value), similarity metric (cosine vs. Pearson), normalization, recency of ratings, and blending of global movie parameters for sparse queries.  Time permitting, the Slope-one method of estimation will be explored.  If possible, a hybrid model will be constructed that blends various combinations of the above into an overall model.  Each technique is briefly discussed.



For cold starts a new approach will be taken.  Up to a certain number X of prior ratings the global average will be blended with similarity.  The weight will decrease by some function f(x), perhaps linearly, and will use variation on the given parameter to attenuate f(x).



%The main objective is to predict how a given user would rate a movie based on the dataset.  To %establish a baseline, the commonly used technique is through collaborative filtering.  Because this %data set has high dimensionality, PCA or SVD will be used to reduce dimension.  A similarity metric of %cosine distance across the ratings will per user will be used.  RMSE error rates will be the final %metric of comparison on a dataset.  Cross-validation will be used for error measurements.
%
%The additional improvements in classification will come from evaluating weighing factors for time of %evaluation.  Several areas to consider are the effects of new users versus established raters, %frequency of ratings in time, time of year, time within a new release window, and release of movie %relative performance review.  Timing permitting additional blended / ensemble methods might be %employed such as gradient descent.  

%%Because I am new to many of these techniques, I request some flexibility in goals and data exploration techniques.



\section{Experiment}
%
%Any pre-processing should be handled in native R or C/C++/Perl if more processing would be required.  %R-studio along with the R framework will be used on the Windows platform.  Visualizations will be %generated through the ggplot2 packages.   %R provides a wealth of custom packages for specific %learning models.
%
%%\section{Relevant Papers}

\section{Conclusion}

{\it Under Construction.}
%Create a reasonable baseline model, tuned appropriately to a collaborative filtering algorithm with %cosine similarity metric, as outlined in the project idea.  Apply PCA or SVD to enhance the baseline. % For the time dependent analysis, provide a method to establish weighting factors in the collaborative %filtering algorithm.  See how the various measurements affect prediction rates in the model.  Add %other techniques, such as gradient descent, as time allows to improve the prediction rate.

%The formatting instructions contained in these style files are summarized in
%sections \ref{gen_inst}, \ref{headings}, and \ref{others} below.

%% \subsection{Keywords for paper submission}
%% Your NIPS paper can be submitted with any of the following keywords (more than one keyword is possible for each paper):

%% \begin{verbatim}
%% Bioinformatics
%% Biological Vision
%% Brain Imaging and Brain Computer Interfacing
%% Clustering
%% Cognitive Science
%% Control and Reinforcement Learning
%% Dimensionality Reduction and Manifolds
%% Feature Selection
%% Gaussian Processes
%% Graphical Models
%% Hardware Technologies
%% Kernels
%% Learning Theory
%% Machine Vision
%% Margins and Boosting
%% Neural Networks
%% Neuroscience
%% Other Algorithms and Architectures
%% Other Applications
%% Semi-supervised Learning
%% Speech and Signal Processing
%% Text and Language Applications

%% \end{verbatim}

% \section{General formatting instructions}
% \label{gen_inst}
% 
% The text must be confined within a rectangle 5.5~inches (33~picas) wide and
% 9~inches (54~picas) long. The left margin is 1.5~inch (9~picas).
% Use 10~point type with a vertical spacing of 11~points. Times New Roman is the
% preferred typeface throughout. Paragraphs are separated by 1/2~line space,
% with no indentation.
% 
% Paper title is 17~point, initial caps/lower case, bold, centered between
% 2~horizontal rules. Top rule is 4~points thick and bottom rule is 1~point
% thick. Allow 1/4~inch space above and below title to rules. All pages should
% start at 1~inch (6~picas) from the top of the page.
% 
% %The version of the paper submitted for review should have ``Anonymous Author(s)'' as the author of the paper.
% 
% For the final version, authors' names are
% set in boldface, and each name is centered above the corresponding
% address. The lead author's name is to be listed first (left-most), and
% the co-authors' names (if different address) are set to follow. If
% there is only one co-author, list both author and co-author side by side.
% 
% Please pay special attention to the instructions in section \ref{others}
% regarding figures, tables, acknowledgments, and references.
% 
% \section{Headings: first level}
% \label{headings}
% 
% First level headings are lower case (except for first word and proper nouns),
% flush left, bold and in point size 12. One line space before the first level
% heading and 1/2~line space after the first level heading.
% 
% \subsection{Headings: second level}
% 
% Second level headings are lower case (except for first word and proper nouns),
% flush left, bold and in point size 10. One line space before the second level
% heading and 1/2~line space after the second level heading.
% 
% \subsubsection{Headings: third level}
% 
% Third level headings are lower case (except for first word and proper nouns),
% flush left, bold and in point size 10. One line space before the third level
% heading and 1/2~line space after the third level heading.
% 
% \section{Citations, figures, tables, references}
% \label{others}
% 
% These instructions apply to everyone, regardless of the formatter being used.
% 
% \subsection{Citations within the text}
% 
% Citations within the text should be numbered consecutively. The corresponding
% number is to appear enclosed in square brackets, such as [1] or [2]-[5]. The
% corresponding references are to be listed in the same order at the end of the
% paper, in the \textbf{References} section. (Note: the standard
% \textsc{Bib\TeX} style \texttt{unsrt} produces this.) As to the format of the
% references themselves, any style is acceptable as long as it is used
% consistently.
% 
% As submission is double blind, refer to your own published work in the 
% third person. That is, use ``In the previous work of Jones et al.\ [4]'',
% not ``In our previous work [4]''. If you cite your other papers that
% are not widely available (e.g.\ a journal paper under review), use
% anonymous author names in the citation, e.g.\ an author of the
% form ``A.\ Anonymous''. 
% 
% 
% \subsection{Footnotes}
% 
% Indicate footnotes with a number\footnote{Sample of the first footnote} in the
% text. Place the footnotes at the bottom of the page on which they appear.
% Precede the footnote with a horizontal rule of 2~inches
% (12~picas).\footnote{Sample of the second footnote}
% 
% \subsection{Figures}
% 
% All artwork must be neat, clean, and legible. Lines should be dark
% enough for purposes of reproduction; art work should not be
% hand-drawn. The figure number and caption always appear after the
% figure. Place one line space before the figure caption, and one line
% space after the figure. The figure caption is lower case (except for
% first word and proper nouns); figures are numbered consecutively.
% 
% Make sure the figure caption does not get separated from the figure.
% Leave sufficient space to avoid splitting the figure and figure caption.
% 
% You may use color figures. 
% However, it is best for the
% figure captions and the paper body to make sense if the paper is printed
% either in black/white or in color.
% \begin{figure}[h]
% \begin{center}
% %\framebox[4.0in]{$\;$}
% \fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
% \end{center}
% \caption{Sample figure caption.}
% \end{figure}
% 
% \subsection{Tables}
% 
% All tables must be centered, neat, clean and legible. Do not use hand-drawn
% tables. The table number and title always appear before the table. See
% Table~\ref{sample-table}.
% 
% Place one line space before the table title, one line space after the table
% title, and one line space after the table. The table title must be lower case
% (except for first word and proper nouns); tables are numbered consecutively.
% 
% \begin{table}[t]
% \caption{Sample table title}
% \label{sample-table}
% \begin{center}
% \begin{tabular}{ll}
% \multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
% \\ \hline \\
% Dendrite         &Input terminal \\
% Axon             &Output terminal \\
% Soma             &Cell body (contains cell nucleus) \\
% \end{tabular}
% \end{center}
% \end{table}
% 
% \section{Final instructions}
% Do not change any aspects of the formatting parameters in the style files.
% In particular, do not modify the width or length of the rectangle the text
% should fit into, and do not change font sizes (except perhaps in the
% \textbf{References} section; see below). Please note that pages should be
% numbered.
% 
% \section{Preparing PostScript or PDF files}
% 
% Please prepare PostScript or PDF files with paper size ``US Letter'', and
% not, for example, ``A4''. The -t
% letter option on dvips will produce US Letter files.
% 
% Fonts were the main cause of problems in the past years. Your PDF file must
% only contain Type 1 or Embedded TrueType fonts. Here are a few instructions
% to achieve this.
% 
% \begin{itemize}
% 
% \item You can check which fonts a PDF files uses.  In Acrobat Reader,
% select the menu Files$>$Document Properties$>$Fonts and select Show All Fonts. You can
% also use the program \verb+pdffonts+ which comes with \verb+xpdf+ and is
% available out-of-the-box on most Linux machines.
% 
% \item The IEEE has recommendations for generating PDF files whose fonts
% are also acceptable for NIPS. Please see
% \url{http://www.emfield.org/icuwb2010/downloads/IEEE-PDF-SpecV32.pdf}
% 
% \item LaTeX users:
% 
% \begin{itemize}
% 
% \item Consider directly generating PDF files using \verb+pdflatex+
% (especially if you are a MiKTeX user). 
% PDF figures must be substituted for EPS figures, however.
% 
% \item Otherwise, please generate your PostScript and PDF files with the following commands:
% \begin{verbatim} 
% dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
% ps2pdf mypaper.ps mypaper.pdf
% \end{verbatim}
% 
% Check that the PDF files only contains Type 1 fonts. 
% %For the final version, please send us both the Postscript file and
% %the PDF file. 
% 
% \item xfig "patterned" shapes are implemented with 
% bitmap fonts.  Use "solid" shapes instead. 
% \item The \verb+\bbold+ package almost always uses bitmap
% fonts.  You can try the equivalent AMS Fonts with command
% \begin{verbatim}
% \usepackage[psamsfonts]{amssymb}
% \end{verbatim}
%  or use the following workaround for reals, natural and complex: 
% \begin{verbatim}
% \newcommand{\RR}{I\!\!R} %real numbers
% \newcommand{\Nat}{I\!\!N} %natural numbers 
% \newcommand{\CC}{I\!\!\!\!C} %complex numbers
% \end{verbatim}
% 
% \item Sometimes the problematic fonts are used in figures
% included in LaTeX files. The ghostscript program \verb+eps2eps+ is the simplest
% way to clean such figures. For black and white figures, slightly better
% results can be achieved with program \verb+potrace+.
% \end{itemize}
% \item MSWord and Windows users (via PDF file):
% \begin{itemize}
% \item Install the Microsoft Save as PDF Office 2007 Add-in from
% \url{http://www.microsoft.com/downloads/details.aspx?displaylang=en\&familyid=4d951911-3e7e-4ae6-b059-a2e79ed87041}
% \item Select ``Save or Publish to PDF'' from the Office or File menu
% \end{itemize}
% \item MSWord and Mac OS X users (via PDF file):
% \begin{itemize}
% \item From the print menu, click the PDF drop-down box, and select ``Save
% as PDF...''
% \end{itemize}
% \item MSWord and Windows users (via PS file):
% \begin{itemize}
% \item To create a new printer
% on your computer, install the AdobePS printer driver and the Adobe Distiller PPD file from
% \url{http://www.adobe.com/support/downloads/detail.jsp?ftpID=204} {\it Note:} You must reboot your PC after installing the
% AdobePS driver for it to take effect.
% \item To produce the ps file, select ``Print'' from the MS app, choose
% the installed AdobePS printer, click on ``Properties'', click on ``Advanced.''
% \item Set ``TrueType Font'' to be ``Download as Softfont''
% \item Open the ``PostScript Options'' folder
% \item Select ``PostScript Output Option'' to be ``Optimize for Portability''
% \item Select ``TrueType Font Download Option'' to be ``Outline''
% \item Select ``Send PostScript Error Handler'' to be ``No''
% \item Click ``OK'' three times, print your file.
% \item Now, use Adobe Acrobat Distiller or ps2pdf to create a PDF file from
% the PS file. In Acrobat, check the option ``Embed all fonts'' if
% applicable.
% \end{itemize}
% 
% \end{itemize}
% If your file contains Type 3 fonts or non embedded TrueType fonts, we will
% ask you to fix it. 
% 
% \subsection{Margins in LaTeX}
%  
% Most of the margin problems come from figures positioned by hand using
% \verb+\special+ or other commands. We suggest using the command
% \verb+\includegraphics+
% from the graphicx package. Always specify the figure width as a multiple of
% the line width as in the example below using .eps graphics
% \begin{verbatim}
%    \usepackage[dvips]{graphicx} ... 
%    \includegraphics[width=0.8\linewidth]{myfile.eps} 
% \end{verbatim}
% or % Apr 2009 addition
% \begin{verbatim}
%    \usepackage[pdftex]{graphicx} ... 
%    \includegraphics[width=0.8\linewidth]{myfile.pdf} 
% \end{verbatim}
% for .pdf graphics. 
% See section 4.4 in the graphics bundle documentation (\url{http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps}) 
%  
% A number of width problems arise when LaTeX cannot properly hyphenate a
% line. Please give LaTeX hyphenation hints using the \verb+\-+ command.
% 
% 
% \subsubsection*{Acknowledgments}
% 
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments go at the end of the paper. Do not include 
% acknowledgments in the anonymized submission, only in the 
% final paper. 
% 

\subsubsection*{References / Papers to Read}

\small{
[1] Xavier Amatriain, Justin Basilico. {\it Netflix Recommendations: Beyond the 5 Stars (Two Parts)}.  The Netflix Tech Blog, 2012. https://medium.com/netflix-techblog/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429. 11/5/2017.

[2] Robert M. Bell, Yehuda Koren. (2007)  {\it Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights}.  Seventh IEEE International Conference on Data Mining. pp. 43-52. IEEE.

[2] Linyuan Lu, Matus Medo, Chi Ho Yeung, Yi-Cheng Zhang, Zi-Ke Zhang, Tao Zhou. (2012) {\it Recommender systems}. In Physics Reports pp. 1-49, Elsevier B. V. 0370-1573.

[3] Michael Hahsler (2017). recommenderlab: Lab for Developing and Testing Recommender Algorithms. R package version 0.2-2. http://lyle.smu.edu/IDA/recommenderlab/

[4] Arkadiusz Paterek, (2007) {\it Improving regularized singular value decomposition for collaborative filtering}.  KDDCup.07 pp. 39-42. ACM 978-1-59593-834-3/07/0008
}
% \subsubsection*{References}
% 
% References follow the acknowledgments. Use unnumbered third level heading for
% the references. Any choice of citation style is acceptable as long as you are
% consistent. It is permissible to reduce the font size to `small' (9-point) 
% when listing the references. {\bf Remember that this year you can use
% a ninth page as long as it contains \emph{only} cited references.}
% 
% \small{
% [1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
% for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
% and T.K. Leen (eds.), {\it Advances in Neural Information Processing
% Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.
% 
% [2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
% Realistic Neural Models with the GEneral NEural SImulation System.}
% New York: TELOS/Springer-Verlag.
% 
% [3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
% and recall at excitatory recurrent synapses and cholinergic modulation
% in rat hippocampal region CA3. {\it Journal of Neuroscience}
% {\bf 15}(7):5249-5262.
% }

\end{document}
